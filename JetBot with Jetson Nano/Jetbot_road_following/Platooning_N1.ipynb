{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adaptive-quilt",
   "metadata": {},
   "source": [
    "### To have communication V2X we'll use MQTT (BLACK JETBOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install MQTT\n",
    "#!pip3 install paho-mqtt\n",
    "\n",
    "# DON'T FORGET ACTIVATE THE MQTT BROKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "liable-perry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded optimized trained weights\n",
      "Created the Pre-Processing Function\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d67938c3c494b4493fa14237102a418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera displayed\n",
      "Created robot instance\n",
      "Listening for MQTT messages...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecceb41e906423ea921de532d8eddbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatSlider(value=0.0, description='y', max=1.0, orientation='vertical'), FloatSlider(value=0.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f26cbdcafa46ba92d1f2afa14f9e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='x', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ebd532eebe45bd863a4d71ff84b8d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created sliders to see what JetBot is thinking\n",
      "JetBot running...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import paho.mqtt.client as mqtt\n",
    "import json\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from jetbot import Camera, bgr8_to_jpeg, Robot\n",
    "from IPython.display import display\n",
    "\n",
    "# Configurar el dispositivo CUDA\n",
    "device = torch.device('cuda')\n",
    "\n",
    "#############################################\n",
    "# Load the TRT optimized model\n",
    "#############################################\n",
    "\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('best_steering_model_xy_trt.pth'))\n",
    "print(\"Loaded optimized trained weights\")\n",
    "\n",
    "#############################################\n",
    "# Creating the Pre-Processing Function\n",
    "#############################################\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "print(\"Created the Pre-Processing Function\")\n",
    "\n",
    "#############################################\n",
    "# Initialize Camera\n",
    "#############################################\n",
    "\n",
    "camera = Camera()\n",
    "image_widget = ipywidgets.Image()\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "display(image_widget)\n",
    "print(\"Camera displayed\")\n",
    "\n",
    "#############################################\n",
    "# Initialize JetBot\n",
    "#############################################\n",
    "\n",
    "robot = Robot()\n",
    "print(\"Created robot instance\")\n",
    "\n",
    "#############################################\n",
    "# MQTT Configuration\n",
    "#############################################\n",
    "\n",
    "MQTT_BROKER = \"192.168.21.1\"  # IP of the MQTT broker\n",
    "MQTT_TOPIC = \"jetbot/control\"\n",
    "\n",
    "# Variables globales para almacenar valores de control (inicialmente en 0)\n",
    "speed_gain = 0.0\n",
    "steering_gain = 0.0\n",
    "steering_kd = 0.0\n",
    "steering_bias = 0.0\n",
    "\n",
    "# Callback cuando se recibe un mensaje MQTT\n",
    "def on_message(client, userdata, message):\n",
    "    global speed_gain, steering_gain, steering_kd, steering_bias  # Aseguramos que modificamos las variables globales\n",
    "    try:\n",
    "        data = json.loads(message.payload.decode(\"utf-8\"))\n",
    "        \n",
    "        # Actualizar los valores de las variables desde MQTT\n",
    "        if \"speed_gain\" in data:\n",
    "            speed_gain = float(data[\"speed_gain\"])\n",
    "        if \"steering_gain\" in data:\n",
    "            steering_gain = float(data[\"steering_gain\"])\n",
    "        if \"steering_kd\" in data:\n",
    "            steering_kd = float(data[\"steering_kd\"])\n",
    "        if \"steering_bias\" in data:\n",
    "            steering_bias = float(data[\"steering_bias\"])\n",
    "        \n",
    "        #print(f\"Received MQTT Data: {data}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing MQTT message: {e}\")\n",
    "\n",
    "# Configurar cliente MQTT\n",
    "client = mqtt.Client()\n",
    "client.on_message = on_message\n",
    "client.connect(MQTT_BROKER)\n",
    "\n",
    "# Suscribirse al tópico\n",
    "client.subscribe(MQTT_TOPIC)\n",
    "client.loop_start()  # Iniciar loop en segundo plano\n",
    "\n",
    "print(\"Listening for MQTT messages...\")\n",
    "\n",
    "#############################################\n",
    "# Display JetBot Predictions\n",
    "#############################################\n",
    "\n",
    "x_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='x')\n",
    "y_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "steering_slider = ipywidgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "speed_slider = ipywidgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='speed')\n",
    "\n",
    "display(ipywidgets.HBox([y_slider, speed_slider]))\n",
    "display(x_slider, steering_slider)\n",
    "print(\"Created sliders to see what JetBot is thinking\")\n",
    "\n",
    "#############################################\n",
    "# Control Loop Function\n",
    "#############################################\n",
    "\n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "\n",
    "def execute(change):\n",
    "    global angle, angle_last, speed_gain, steering_gain, steering_kd, steering_bias\n",
    "    image = change['new']\n",
    "    xy = model_trt(preprocess(image)).detach().float().cpu().numpy().flatten()\n",
    "    x = xy[0]\n",
    "    y = (0.5 - xy[1]) / 2.0\n",
    "    \n",
    "    x_slider.value = x\n",
    "    y_slider.value = y\n",
    "    \n",
    "    speed_slider.value = speed_gain  # Ahora se usa la variable en lugar del slider\n",
    "    \n",
    "    angle = np.arctan2(x, y)\n",
    "    pid = angle * steering_gain + (angle - angle_last) * steering_kd\n",
    "    angle_last = angle\n",
    "    \n",
    "    steering_slider.value = pid + steering_bias\n",
    "    \n",
    "    robot.left_motor.value = max(min(speed_slider.value + steering_slider.value, 1.0), 0.0)\n",
    "    robot.right_motor.value = max(min(speed_slider.value - steering_slider.value, 1.0), 0.0)\n",
    "    \n",
    "execute({'new': camera.value})\n",
    "\n",
    "#############################################\n",
    "# Attach Neural Network Execution to Camera\n",
    "#############################################\n",
    "\n",
    "camera.observe(execute, names='value')\n",
    "print(\"JetBot running...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acoustic-carroll",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jetbot stopped...\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()\n",
    "\n",
    "camera.stop()\n",
    "\n",
    "print(\"Jetbot stopped...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "virgin-factor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
