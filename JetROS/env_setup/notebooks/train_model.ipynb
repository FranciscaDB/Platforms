{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4743c4c7-b1a4-4e9e-8619-a75f74e05a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created\n",
      "Dataset splitted into test (0.1) and train (0.9)\n",
      "Created data loaders to load data in batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/nelson/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network defined: resnet18\n",
      "0.784753, 5.500496\n",
      "1.624622, 1.208084\n",
      "0.624026, 18.172390\n",
      "0.200996, 12.848871\n",
      "0.125467, 2.985002\n",
      "0.112020, 0.453683\n",
      "0.060057, 0.274478\n",
      "0.074749, 0.090432\n",
      "0.050649, 0.387439\n",
      "0.046372, 0.262541\n",
      "0.033214, 0.049774\n",
      "0.024448, 0.048141\n",
      "0.047531, 0.053305\n",
      "0.034870, 0.035154\n",
      "0.028830, 0.141492\n",
      "0.040279, 0.064277\n",
      "0.039372, 0.088067\n",
      "0.028173, 0.076029\n",
      "0.024259, 0.040744\n",
      "0.014244, 0.077296\n",
      "0.021646, 0.101710\n",
      "0.026223, 0.059138\n",
      "0.033173, 0.079881\n",
      "0.013856, 0.031342\n",
      "0.018522, 0.050789\n",
      "0.041958, 0.049411\n",
      "0.037880, 0.035152\n",
      "0.068014, 0.046873\n",
      "0.028280, 0.100623\n",
      "0.043492, 0.064927\n",
      "0.023100, 0.046138\n",
      "0.027357, 0.058754\n",
      "0.040823, 0.041786\n",
      "0.030638, 0.033628\n",
      "0.061644, 0.059996\n",
      "0.037168, 0.084861\n",
      "0.013792, 0.099750\n",
      "0.032866, 0.044895\n",
      "0.029486, 0.103327\n",
      "0.021416, 0.066158\n",
      "0.016322, 0.047163\n",
      "0.025563, 0.054298\n",
      "0.021803, 0.093469\n",
      "0.034151, 0.037917\n",
      "0.016867, 0.071083\n",
      "0.028673, 0.078881\n",
      "0.013592, 0.060048\n",
      "0.007643, 0.058922\n",
      "0.015824, 0.042085\n",
      "0.021162, 0.049677\n",
      "0.013534, 0.049970\n",
      "0.004326, 0.040949\n",
      "0.019451, 0.048674\n",
      "0.008662, 0.046353\n",
      "0.007259, 0.047929\n",
      "0.007415, 0.042790\n",
      "0.003405, 0.045780\n",
      "0.007789, 0.057766\n",
      "0.013948, 0.042874\n",
      "0.010898, 0.055123\n",
      "0.014664, 0.063871\n",
      "0.020548, 0.050888\n",
      "0.011585, 0.065163\n",
      "0.040152, 0.050854\n",
      "0.013934, 0.043140\n",
      "0.015418, 0.046118\n",
      "0.010440, 0.034365\n",
      "0.019122, 0.080433\n",
      "0.012371, 0.048827\n",
      "0.030540, 0.046833\n",
      "Training ready\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import PIL.Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def get_x(path, width):\n",
    "    \"\"\"Gets the x value from the image filename\"\"\"\n",
    "    return (float(int(path.split(\"_\")[1])) - width/2) / (width/2)\n",
    "\n",
    "def get_y(path, height):\n",
    "    \"\"\"Gets the y value from the image filename\"\"\"\n",
    "    return (float(int(path.split(\"_\")[2])) - height/2) / (height/2)\n",
    "\n",
    "class XYDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, directory, random_hflips=False):\n",
    "        self.directory = directory\n",
    "        self.random_hflips = random_hflips\n",
    "        self.image_paths = glob.glob(os.path.join(self.directory, '*.jpg'))\n",
    "        self.color_jitter = transforms.ColorJitter(0.3, 0.3, 0.3, 0.3)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        \n",
    "        image = PIL.Image.open(image_path)\n",
    "        width, height = image.size\n",
    "        x = float(get_x(os.path.basename(image_path), width))\n",
    "        y = float(get_y(os.path.basename(image_path), height))\n",
    "      \n",
    "        if float(np.random.rand(1)) > 0.5:\n",
    "            image = transforms.functional.hflip(image)\n",
    "            x = -x\n",
    "        \n",
    "        image = self.color_jitter(image)\n",
    "        image = transforms.functional.resize(image, (224, 224))\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        image = image.numpy()[::-1].copy()\n",
    "        image = torch.from_numpy(image)\n",
    "        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        return image, torch.tensor([x, y]).float()\n",
    "    \n",
    "dataset = XYDataset('dataset_xy', random_hflips=False)\n",
    "\n",
    "print(\"Dataset created\")\n",
    "\n",
    "#############################################\n",
    "# Split dataset into train and test sets\n",
    "#############################################\n",
    "\n",
    "test_percent = 0.1\n",
    "num_test = int(test_percent * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])\n",
    "\n",
    "print(f\"Dataset splitted into test ({test_percent}) and train ({1 - test_percent})\")\n",
    "\n",
    "#############################################\n",
    "# Create data loaders to load data in batches\n",
    "#############################################\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(\"Created data loaders to load data in batches\")\n",
    "\n",
    "#############################################\n",
    "# Define Neural Network Model \n",
    "#############################################\n",
    "\n",
    "# More details on ResNet-18 : https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py\n",
    "# More Details on Transfer Learning: https://www.youtube.com/watch?v=yofjFQddwHE \n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# ResNet model has fully connect (fc) final layer with 512 as ``in_features`` and we will be training for regression thus ``out_features`` as 1\n",
    "# Finally, we transfer our model for execution on the GPU\n",
    "\n",
    "model.fc = torch.nn.Linear(512, 2)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Neural network defined: resnet18\")\n",
    "\n",
    "#############################################\n",
    "# Train Regression\n",
    "#############################################\n",
    "\n",
    "NUM_EPOCHS = 70\n",
    "BEST_MODEL_PATH = 'best_steering_model_xy.pth'\n",
    "best_loss = 1e9\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for images, labels in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        train_loss += float(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    for images, labels in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        loss = F.mse_loss(outputs, labels)\n",
    "        test_loss += float(loss)\n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    print('%f, %f' % (train_loss, test_loss))\n",
    "    if test_loss < best_loss:\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        best_loss = test_loss\n",
    "        \n",
    "print(\"Training ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a26a521-fd98-4fb9-a241-8159e7c27779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
