{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ba441f-8a69-4d99-bd3f-b8b6da0df3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usb_cam node started.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import signal\n",
    "\n",
    "# Start the usb_cam node in the background\n",
    "usb_cam_process = subprocess.Popen(\n",
    "    ['ros2', 'run', 'usb_cam', 'usb_cam_node_exe'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE,\n",
    "    preexec_fn=os.setsid # esto es clave para agrupar procesos\n",
    ")\n",
    "\n",
    "print(\"usb_cam node started.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b14df9c9-26e5-4a9d-83c8-88da0258a73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint0\n",
      "[12/31/1969-20:48:12] [TRT] [W] Using an engine plan file across different models of devices is not recommended and is likely to affect performance or even cause errors.\n",
      "Loaded optimized trained weights\n",
      "Checkpoint1\n",
      "Checkpoint2\n",
      "Created the Pre-Processing Function\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda')\n",
    "print(\"Checkpoint0\")\n",
    "#############################################\n",
    "# Load the TRT optimized model\n",
    "#############################################\n",
    "\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('best_steering_model_xy_trt.pth'))\n",
    "\n",
    "print(\"Loaded optimized trained weights\")\n",
    "\n",
    "# Creating the Pre-Processing Function\n",
    "#############################################\n",
    "\n",
    "# We have now loaded our model, but there's a slight issue. The format that we trained our model doesn't exactly match the format of the camera. To do that, we need to do some preprocessing. This involves the following steps:\n",
    "\n",
    "# 1. Convert from HWC layout to CHW layout\n",
    "# 2. Normalize using same parameters as we did during training (our camera provides values in [0, 255] range and training loaded images in [0, 1] range so we need to scale by 255.0\n",
    "# 3. Transfer the data from CPU memory to GPU memory\n",
    "# 4. Add a batch dimension\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "print(\"Checkpoint1\")\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "print(\"Checkpoint2\")\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image).resize((224, 224))\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "print(\"Created the Pre-Processing Function\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916cb053-3dc2-4470-93cd-9d96000504c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28732c0cecb14b30b464e69a1c7145a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='speed gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645b3562cd634e38830d06f4891cb11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.2, description='steering gain', max=1.0, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4713d5d3bb24d1caf2528975e679213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering kd', max=0.5, step=0.001)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acade139ecd84d39aa6890615c671405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering bias', max=0.3, min=-0.3, step=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3719b135d64ee099f3a744428c3ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='x', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a16a3c13ad4f2e8eccb8684c7ef71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='y', max=1.0, orientation='vertical')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e717e44bae804a498e979225064bdcae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.0, description='steering', max=1.0, min=-1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fec83a2e0af4711816c7dff216d388f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Sliders de parametros\n",
    "speed_gain_slider = widgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed gain')\n",
    "steering_gain_slider = widgets.FloatSlider(min=0.0, max=1.0, step=0.01, value=0.2, description='steering gain')\n",
    "steering_dgain_slider = widgets.FloatSlider(min=0.0, max=0.5, step=0.001, value=0.0, description='steering kd')\n",
    "steering_bias_slider = widgets.FloatSlider(min=-0.3, max=0.3, step=0.01, value=0.0, description='steering bias')\n",
    "\n",
    "display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)\n",
    "\n",
    "# Sliders para mostrar predicciones\n",
    "x_slider = widgets.FloatSlider(min=-1.0, max=1.0, description='x')\n",
    "y_slider = widgets.FloatSlider(min=0, max=1.0, orientation='vertical', description='y')\n",
    "steering_slider = widgets.FloatSlider(min=-1.0, max=1.0, description='steering')\n",
    "\n",
    "display(x_slider, y_slider, steering_slider)\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg')\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99a3dd90-e1c3-4abf-abd6-bd4d3ef1b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rclpy\n",
    "from rclpy.node import Node\n",
    "from sensor_msgs.msg import Image as ROSImage\n",
    "from cv_bridge import CvBridge\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from threading import Thread\n",
    "import numpy as np\n",
    "import time\n",
    "from geometry_msgs.msg import Twist\n",
    "\n",
    "def bgr8_to_jpeg(value):\n",
    "    return cv2.imencode('.jpg', value)[1].tobytes()\n",
    "    \n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "bridge = CvBridge()\n",
    "\n",
    "class ImageSubscriber(Node):\n",
    "    def __init__(self):\n",
    "        super().__init__('image_subscriber')\n",
    "        self.subscription = self.create_subscription(\n",
    "            ROSImage,\n",
    "            '/image_raw',\n",
    "            self.listener_callback,\n",
    "            10)\n",
    "        # Crear publisher para el mensaje Twist\n",
    "        self.twist_publisher = self.create_publisher(Twist, 'JetBot1/target', 10)\n",
    "    \n",
    "    def listener_callback(self, msg):\n",
    "        global angle, angle_last\n",
    "        frame = bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\n",
    "        \n",
    "        # Mostrar imagen\n",
    "        image_widget.value = bgr8_to_jpeg(frame)\n",
    "        \n",
    "        # Inference\n",
    "        xy = model_trt(preprocess(frame)).detach().float().cpu().numpy().flatten()\n",
    "        x = xy[0]\n",
    "        y = (0.5 - xy[1]) / 2.0\n",
    "        \n",
    "        # Actualizar sliders\n",
    "        x_slider.value = x\n",
    "        y_slider.value = y\n",
    "        #speed_slider.value = speed_gain_slider.value\n",
    "\n",
    "        angle = np.arctan2(x, y)\n",
    "        pid = angle * steering_gain_slider.value + (angle - angle_last) * steering_dgain_slider.value\n",
    "        angle_last = angle\n",
    "        steering_slider.value = pid + steering_bias_slider.value\n",
    "        \n",
    "        # Crear y publicar mensaje Twist\n",
    "        twist_msg = Twist()\n",
    "        twist_msg.linear.x = speed_gain_slider.value     # puedes modificar según tu lógica\n",
    "        twist_msg.angular.z = steering_slider.value\n",
    "        self.twist_publisher.publish(twist_msg)\n",
    "\n",
    "def start_ros_node():\n",
    "    if not rclpy.ok():\n",
    "        rclpy.init()\n",
    "    node = ImageSubscriber()\n",
    "    rclpy.spin(node)\n",
    "    node.destroy_node()\n",
    "    rclpy.shutdown()\n",
    "\n",
    "# Iniciar nodo en segundo plano\n",
    "ros_thread = Thread(target=start_ros_node, daemon=True)\n",
    "ros_thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a28d94-5be7-4c58-8151-2f45be5983fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'usb_cam_process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msignal\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m os\u001b[38;5;241m.\u001b[39mkillpg(os\u001b[38;5;241m.\u001b[39mgetpgid(\u001b[43musb_cam_process\u001b[49m\u001b[38;5;241m.\u001b[39mpid), signal\u001b[38;5;241m.\u001b[39mSIGINT)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'usb_cam_process' is not defined"
     ]
    }
   ],
   "source": [
    "os.killpg(os.getpgid(usb_cam_process.pid), signal.SIGINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22bbe8c-b8bf-4868-9120-82a76773d036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
